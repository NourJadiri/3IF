---
title: "TP"
output: html_notebook
---

# Tests de générateurs pseudo aléatoires

## Question 1 : implémentation des algorithmes

---
```{r}
congruenceLineaire <- function(graine , a , b , m , n){
  seed <- rep(graine,n)

  for(i in 2:n){
    seed[i] <- (a*seed[i-1] + b)%%m
  }

  return (seed)
}
```

### RANDU
---
```{r}
RANDU <- function(graine = 69420 , n){
  a <- 65539
  b <- 0
  m <- 2^31
  return (congruenceLineaire(graine, a , b , m , n))
}
```


### Standard Minimal
```{r}
standardMinimal <- function(graine = 69420, n){
  a <- 16807
  b <- 0
  m <- 2^31 - 1

  return (congruenceLineaire(graine , a , b , m , n))
}
```

### VonNeumann
```{r}
VonNeumann <- function(n, p=1, graine)
{
  x <-  rep(graine,n*p+1)
  for(i in 2:(n*p+1))
  {
    numbers <- strsplit(format(x[i-1]^2,scientific=FALSE),'')[[1]]
    while(length(numbers)>4){
      numbers <- numbers[2:(length(numbers)-1)]
    }
    x[i] <- as.numeric(numbers)%*%(10^seq(length(numbers)-1,0,-1))
  }
  x <- matrix(x[2:(n*p+1)],nrow=n,ncol=p)
  return(x)
}

```

### Mersenne-Twister
```{r}
MersenneTwister <- function(n, p=1, graine)
{
  set.seed(graine,kind='Mersenne-Twister')
  x <- sample.int(2^32-1,n*p)
  x <- matrix(x,nrow=n,ncol=p)
  return(x)
}

```

## Question 2 : tests visuels des générateurs

### 2.1 : historgramme de distributions des différents générateurs

```{r}
test_visuel <- function(k) {
  par(mfrow = c(2,2))
  hist(RANDU(graine = 215, n = k) , xlab = "Valeur" , ylab = "fréquence" , main = "RANDU")
  hist(standardMinimal(graine = 215 , n = k) , xlab = "Valeur" , ylab = "fréquence" , main = "Standard Minimal")
  hist(VonNeumann(n = k , graine = 215), main = "Von Neumann")
  hist(MersenneTwister(n = k, graine = 215), main = "Mersenne-Twister")
}

```

```{r}
test_visuel(100)
```
#### Commentaire
* <b>Von Neumann</b>

Le générateur de nombres aléatoires de Von Neumann produit plus de nombres entre 0 et 2000 que entre 2000 et 9999 en raison de l'étape de troncature dans l'algorithme.
Lorsque le nombre au carré est inférieur à 1000, il conserve ses trois chiffres, donc le nombre généré reste dans l'intervalle de 0 à 999. En revanche, lorsque le nombre au carré est compris entre 1000 et 9999, la troncature supprime le premier et le dernier chiffre, ce qui donne un nombre entre 0 et 999.

Ainsi, plusieurs nombres au carré dans l'intervalle de 1000 à 9999 sont associés à la même valeur tronquée dans l'intervalle de 0 à 999. Par conséquent, il y a moins de nombres uniques dans l'intervalle de 2000 à 9999 par rapport à l'intervalle de 0 à 2000.

* <b>RANDU</b>

Le générateur RANDU fonctionne en appliquant de manière répétée une formule congruentielle linéaire, où chaque nombre est généré en multipliant le nombre précédent par un multiplicateur constant, puis en prenant le modulo du résultat. Le problème avec RANDU réside dans le choix de ses paramètres, qui entraînent des propriétés indésirables.

Un problème majeur est la présence d'une période courte. La séquence de nombres générés par RANDU se répète après un nombre relativement faible d'itérations. Cela signifie que le générateur va parcourir un ensemble limité de valeurs, ce qui entraîne une distribution non uniforme.

De plus, RANDU présente de mauvaises propriétés spectrales, ce qui signifie que les nombres générés ont tendance à se situer sur un nombre limité de plans ou d'hyperplans dans l'espace des nombres. Cet effet de regroupement introduit des motifs et des corrélations dans la séquence générée, s'éloignant ainsi d'une distribution uniforme.

* <b>Standard Minimal </b>

Il est conçu pour fournir une meilleure qualité de génération de nombres aléatoires par rapport à des générateurs plus simples comme RANDU.

Le générateur StandardMinimal utilise des paramètres spécifiques et des techniques de permutation pour améliorer les propriétés statistiques de la séquence de nombres générés. Il a une période beaucoup plus longue, ce qui signifie qu'il génère une séquence de nombres aléatoires qui se répète après un nombre beaucoup plus grand d'itérations. Cela contribue à une meilleure distribution des nombres aléatoires et réduit les effets indésirables tels que la corrélation et les biais.

* <b> Mersenne-Twister </b>

Le principal avantage du générateur Mersenne Twister est sa période extrêmement longue. Il peut générer des séquences de nombres aléatoires de qualité avec une période de 2^19937 - 1, ce qui signifie qu'il peut générer un nombre immense de nombres avant que la séquence ne se répète.

De plus, le générateur Mersenne Twister présente de bonnes propriétés statistiques. Il produit des nombres qui sont largement distribués et qui semblent indépendants les uns des autres. Il a une excellente uniformité, une faible corrélation et un bon mélange des bits, ce qui le rend adapté à une large gamme d'applications nécessitant une génération de nombres aléatoires de haute qualité.

### 2.2 : Traçage de $S_n = f(S_{n-1})$

```{r}
n <- 100
u_RANDU <- RANDU(graine = 215, n =100)
u_SM <- standardMinimal(graine = 215, n =100)
u_VonNeumann <- VonNeumann(n = 100, graine = 215)
u_MersenneTwister <- MersenneTwister(n = 100 , graine = 215)


plot(u_RANDU[1:(n-1)] , u_RANDU[2:n] , xlab = "S(n-1)" , ylab = "(S_n)", main = "RANDU")
plot(u_SM[1:(n-1)] , u_SM[2:n] , xlab = "S(n-1)" , ylab = "(S_n)" , main = "Standard Minimal")
plot(u_VonNeumann[1:(n-1)] , u_VonNeumann[2:n] , xlab = "S(n-1)" , ylab = "(S_n)", main = "von Neumann")
plot(u_MersenneTwister[1:(n-1)] , u_MersenneTwister[2:n] , xlab = "S(n-1)" , ylab = "(S_n)" , main = "Mersenne-Twister")
```
* <b>RANDU</b>
A première vue, le traçage $S_n = f(S_{n-1}) pour RANDU ne montre aucun motif répétitif, ni cluster. Cependant, il est important de noter que RANDU est connu pour avoir des propriétés statistiques indésirables, telles qu'une période courte et une distribution non uniforme (en raison de sa fonction génératrice). Bien que cela ne soit pas clairement visible dans le graphique, ces problèmes peuvent avoir un impact sur la qualité des nombres pseudo-aléatoires générés par cet algorithme.

* <b> Standard Minimal </b>
Tout comme RANDU, le traçage $S_n = f(S_{n-1}) pour Standard Minimal ne montre aucun motif répétitif, ni cluster. En effet, le générateur a été conçu pour améliorer la qualité des nombres aléatoires générés par rapport à des générateurs plus simples (RANDU). On peut voir alors que la distribution du nuage de points est plus homogène que celle de RANDU.

La faible présence de motifs/clusters pour ces deux algorithmes vient appuyer les distributions observées grâce aux différents histogrammes de la question précédente.

* <b> Von Neumann </b>
La présence de clusters évidents dans la visualisation de Sn en fonction de S(n-1) pour le générateur de Von Neumann peut être interprétée comme un signe de non-uniformité dans la distribution des nombres pseudo-aléatoires générés. Ces clusters indiquent que les valeurs générées tendent à être regroupées dans certaines plages spécifiques plutôt que d'être uniformément réparties sur toute la plage de valeurs possibles.

D'un point de vue probabiliste, cela peut être problématique car cela signifie que certaines valeurs sont plus susceptibles d'être générées que d'autres. Cela peut introduire un biais dans les résultats d'une simulation ou d'une analyse statistique qui utilise ces nombres pseudo-aléatoires.

De plus, les clusters observés peuvent également indiquer une dépendance entre les nombres générés. Dans un générateur pseudo-aléatoire idéal, les valeurs successives devraient être indépendantes les unes des autres. Cependant, la présence de clusters suggère une corrélation ou une dépendance entre les nombres générés, ce qui peut affecter la propriété d'indépendance statistique souhaitée pour les applications probabilistes.

* <b> Mersenne-Twister </b>
Dans le cas du générateur Mersenne-Twister, la visualisation de $S_n$ en fonction de $S_{n-1}$ montre une distribution uniforme des points sans la présence de clusters ou de motifs apparents. Cela indique que les nombres générés par le générateur Mersenne-Twister sont indépendants les uns des autres et qu'ils sont répartis de manière équilibrée sur toute la plage de valeurs possibles.

D'un point de vue probabiliste, cette distribution uniforme suggère que chaque nombre généré par le Mersenne-Twister a la même probabilité d'apparaître. Cela correspond à l'une des propriétés souhaitées pour un générateur pseudo-aléatoire de haute qualité.

De plus, la longue période du Mersenne-Twister `(2^19937 - 1)` contribue à assurer une faible corrélation entre les nombres générés successivement. Cela est crucial pour de nombreuses applications probabilistes qui dépendent de l'indépendance statistique des nombres aléatoires.

## Test de fréquence monobit

La fonction qui nous est fournie permet de convertir tout nombre entier en séquence de 32 bits
```{r}
binary <- function(x)
{
  if((x<2^31)&(x>=0))
    return( as.integer(intToBits(as.integer(x))) )
  else{
    if((x<2^32)&(x>0))
      return( c(binary(x-2^31)[1:31], 1) )
    else{
      cat('Erreur dans binary : le nombre etudie n est pas un entier positif en 32 bits.\n')
      return(c())
    }
  }
}

```


### Implémentation
On commence par implémenter la fonction de calcul du nombre de bits à 1

```{r}
Frequency <- function(x,nb = 32){
  s <- rep(0,length(x))

  # Conversion en séquence de bits
  for(i in seq_along(x)){
    bSeq <- binary(x[i])[1:nb]
    s[i] <- sum(2 * bSeq[1:nb] - 1)
  }

  # Calcul de s_obs
  s_obs <- abs(sum(s))/sqrt(nb * length(x))

  p_value <- 2 * (1 - pnorm(s_obs))

  return (p_value)
}
```

### Test de fréquence monobit
La première étape consiste à prendre 100 graines aléatoires entre 1 et 10000.
On utilise la fonction `set.seed()` afin que la fonction `sample.int()` retourne la même séquence.
```{r}
set.seed(555)
seeds <- sample.int(10000 , 100)
```
On procède ensuite à la génération des séquences grâce aux générateurs pseudo-aléatoires étudiés.
Les vecteurs `freq_GENERATEUR` stockent les différentes p-valeurs retournées par la fonction `Frequency(x , nb)` pour chaque séquence aléatoire générée par une graine différente.
```{r}
freq_RANDU <- NULL
freq_SM <- NULL
freq_VonNeumann <- NULL
freq_MersenneTwister <- NULL

# On parcourt le vecteur de seeds
for(i in seq_along(seeds)){
  # Pour chaque graine, on génère une séquence
  u_RANDU <- RANDU(graine = seeds[i], n = 200)
  u_SM <- standardMinimal(graine = seeds[i] , n = 200)
  u_VonNeumann <- VonNeumann(graine = seeds[i] , n = 200)[,1]
  u_MersenneTwister <- MersenneTwister(graine = seeds[i] , n = 200)[,1]

  # Ensuite on rajoute la p-valeur retournée par la séquence du générateur correspondant dans le vecteur correspondant
  freq_RANDU <- c(freq_RANDU,Frequency(u_RANDU , 31))
  freq_SM <- c(freq_SM,Frequency(u_SM , 31))
  freq_VonNeumann <- c(freq_VonNeumann,Frequency(u_VonNeumann , 14))
  freq_MersenneTwister <- c(freq_MersenneTwister,Frequency(u_MersenneTwister))
}
```
La prochaine étape consiste à effectuer une étude de la qualité des différents générateurs.
On commence d'abord par extraire le nombre de fois qu'une p-valeur est inférieure à notre seuil de signification (0.01), cela pourra nous donner une indication de combien de valeurs <i>supposées aléatoires</i> pouvons nous être surs de rejetter pour chaque générateur.
```{r}
# Nombre de valeurs inferieures à 0.01
n_RANDU <- length(which(freq_RANDU < 0.01))
n_SM <- length(which(freq_SM < 0.01))
n_VonNeumann <- length(which(freq_VonNeumann < 0.01))
n_MersenneTwister <- length(which(freq_MersenneTwister < 0.01))
```
Un autre indicateur interessant est la valeur moyenne de la p-valeur pour chaque séquence de fréquences monobit générée.
```{r}
#Calcul de la p_value moyenne pour chacun des générateurs
avg_pvalue_RANDU <- mean(freq_RANDU)
avg_pvalue_SM <- mean(freq_SM)
avg_pvalue_VonNeumann <- mean(freq_VonNeumann)
avg_pvalue_MersenneTwister <- mean(freq_MersenneTwister)
```

On remarque que Mersenne-Twister et StandardMinimal ont de bien meilleures performances que les autres algorithmes. Cela vient confirmer la distribution qu'on a plot plus haut, qui montre que les distributions de ces deux algorithmes sont celles qui se rapprochent le plus d'une loi uniforme.

Le nombre de p-value inférieures à 0,01 sont les suivants :

* Mersenne-Twister : 0
* RANDU : 54
* StandardMinimal : 2
* VonNeumann : 98

Cela suggère que pour les séquences générées :

<b>Mersenne-Twister</b> : Aucune p-valeur n'est inférieure à 0,01. Cela indique que la séquence générée par Mersenne-Twister semble être en conformité avec la distribution aléatoire équilibrée, du moins en termes de ce test spécifique.

<b>RANDU</b> : 54 p-valeurs sont inférieures à 0,01. Cela suggère que la séquence générée par RANDU présente un déséquilibre significatif et ne suit pas une distribution aléatoire équilibrée selon ce test. Il peut y avoir un biais ou une structure non aléatoire dans la séquence.

<b>StandardMinimal</b> : 2 p-valeurs sont inférieures à 0,01. Cela suggère que la séquence générée par StandardMinimal présente également un léger déséquilibre, et ne suit pas une distribution aléatoire équilibrée selon ce test. Le générateur reste cependant de meilleure qualité que RANDU.

<b>VonNeumann</b> : 98 p-valeurs sont inférieures à 0,01. Cela indique que la séquence générée par VonNeumann présente un déséquilibre important et ne suit pas une distribution aléatoire équilibrée selon ce test.

Aussi, nous avons calculé la p_value moyenne pour chaque séquence générée :

* RANDU : 0.197
* StandardMinimal : 0.504
* Von Neumann : 0.014
* Mersenne-Twister : 0.493

Bien que la moyenne de ces p_value peut suggérer que Standard Minimal est meilleur que Mersenne-Twister, il faut garder en tête que le générateur de Mersenne-Twister n'a renvoyé aucune p_valeur inférieure au niveau de signification.

### Test des runs
```{r}
Runs <- function(x , nb = 32){
  tau <- 2/(sqrt(nb*length(x)))
  bSeq <- c()

  # Pre-test
  for(i in seq_along(x)){
    # Concaténation de toutes les séquences de bits
    bSeq <- c(bSeq , binary(x[i])[1:nb])
  }

  pi <- sum(bSeq == 1)/length(bSeq)

  # Si le pretest échoue, on retourne p_value = 0
  if(abs(pi - 0.5) >= tau){
    return(0)
  }

  # Sinon on continue

  V_n <- sum(bSeq[-length(bSeq)] != bSeq[-1])
  V_n <- V_n + 1

  p_value <- 2*(1 - pnorm(abs(V_n - 2 * nb*length(x) * pi * (1-pi))/(2 * sqrt(nb*length(x)) * pi * (1-pi))))

  return(p_value)
}
```
On reprend alors les tests sur les séquences générées précédemment
```{r}
runs_RANDU <- NULL
runs_SM <- NULL
runs_VonNeumann <- NULL
runs_MersenneTwister <- NULL

for(i in seq_along(seeds)){
  # Pour chaque graine, on génère une séquence
  u_RANDU <- RANDU(graine = seeds[i], n = 200)
  u_SM <- standardMinimal(graine = seeds[i] , n = 200)
  u_VonNeumann <- VonNeumann(graine = seeds[i] , n = 200)[,1]
  u_MersenneTwister <- MersenneTwister(graine = seeds[i] , n = 200)[,1]

  runs_RANDU <- c(runs_RANDU,Runs(u_RANDU , 31))
  runs_SM <- c(runs_SM,Runs(u_SM , 31))
  runs_VonNeumann <- c(runs_VonNeumann,Runs(u_VonNeumann , 14))
  runs_MersenneTwister <- c(runs_MersenneTwister,Runs(u_MersenneTwister))
}

# Nombre de p-valeurs inferieures à 0.01
n_RANDU <- length(which(runs_RANDU < 0.01))
n_SM <- length(which(runs_SM < 0.01))
n_VonNeumann <- length(which(runs_VonNeumann < 0.01))
n_MersenneTwister <- length(which(runs_MersenneTwister < 0.01))
#Calcul de la p_value moyenne pour chacun des générateurs
avg_pvalue_RANDU <- mean(runs_RANDU)
avg_pvalue_SM <- mean(runs_SM)
avg_pvalue_VonNeumann <- mean(runs_VonNeumann)
avg_pvalue_MersenneTwister <- mean(runs_MersenneTwister)
```
Le nombre de p-value inférieures à 0,01 sont les suivants :

* Mersenne-Twister : 0
* RANDU : 43
* StandardMinimal : 3
* VonNeumann : 100

Cela suggère que pour les séquences générées :

<b>Mersenne-Twister</b> : Aucune p-valeur n'est inférieure à 0,01. Cela indique que la séquence générée par Mersenne-Twister semble être en conformité avec la distribution aléatoire équilibrée, du moins en termes de ce test spécifique.

<b>RANDU</b> : 43 p-valeurs sont inférieures à 0,01. Cela suggère que la séquence générée par RANDU présente un déséquilibre significatif et ne suit pas une distribution aléatoire équilibrée selon ce test. Il peut y avoir un biais ou une structure non aléatoire dans la séquence.

<b>StandardMinimal</b> : 3 p-valeurs sont inférieures à 0,01. Cela suggère que la séquence générée par StandardMinimal présente également un léger déséquilibre, et ne suit pas une distribution aléatoire équilibrée selon ce test. Le générateur reste cependant de meilleure qualité que RANDU.

<b>VonNeumann</b> : 100 p-valeurs sont inférieures à 0,01. Cela indique que la séquence générée par VonNeumann présente un déséquilibre important et ne suit pas une distribution aléatoire équilibrée selon ce test. L'hypothèse de la distribution des nombres uniforme est à rejeter.

Aussi, nous avons calculé la p_value moyenne pour chaque séquence générée :

* RANDU : 0.260
* StandardMinimal : 0.0.487
* Von Neumann : 0
* Mersenne-Twister : 0.507

Bien que la moyenne de ces p_value peut suggérer que Standard Minimal est meilleur que Mersenne-Twister, il faut garder en tête que le générateur de Mersenne-Twister n'a renvoyé aucune p_valeur inférieure au niveau de signification.

Ce test aussi montre que en moyenne, le générateur de Mersenne-Twister présente de meilleures performances que le générateur Standard Minimal. Cela est du au fait que les valeurs générées par `Standard Minimal`peuvent suivre des motifs.

### Test d'ordre
```{r}
order_RANDU <- NULL
order_SM <- NULL
order_VonNeumann <- NULL
order_MersenneTwister <- NULL

for(i in seq_along(seeds)){
  # Pour chaque graine, on génère une séquence
  u_RANDU <- RANDU(graine = seeds[i], n = 200)
  u_SM <- standardMinimal(graine = seeds[i] , n = 200)
  u_VonNeumann <- VonNeumann(graine = seeds[i] , n = 200)[,1]
  u_MersenneTwister <- MersenneTwister(graine = seeds[i] , n = 200)[,1]

  order_RANDU <- c(order_RANDU,order.test(u_RANDU , d = 4, echo = FALSE)$p.value)
  order_SM <- c(order_SM,order.test(u_SM , d = 4, echo = FALSE)$p.value)
  order_VonNeumann <- c(order_VonNeumann,order.test(u_VonNeumann , d = 4, echo = FALSE)$p.value)
  order_MersenneTwister <- c(order_MersenneTwister,order.test(u_MersenneTwister , d = 4, echo = FALSE)$p.value)
}

# Nombre de p-valeurs inferieures à 0.01
n_RANDU <- length(which(order_RANDU < 0.01))
n_SM <- length(which(order_SM < 0.01))
n_VonNeumann <- length(which(order_VonNeumann < 0.01))
n_MersenneTwister <- length(which(order_MersenneTwister < 0.01))
```
Le nombre de p-value inférieures à 0,01 sont les suivants :

* Mersenne-Twister : 1
* RANDU : 3
* StandardMinimal : 1
* VonNeumann : 83

<b>Mersenne-Twister</b> : Le générateur Mersenne-Twister présente seulement 1 p-valeur inférieure à 0,01 lors du test d'ordre. Cela suggère que ce générateur produit des séquences de nombres aléatoires qui sont relativement bien réparties et ne montrent pas de structure ou de biais significatifs.

<b>RANDU</b> : Le générateur RANDU présente 3 p-valeurs inférieures à 0,01 lors du test d'ordre. Cela indique que les séquences générées par RANDU peuvent présenter des motifs ou des biais non aléatoires, ce qui les rend moins appropriées pour des applications nécessitant une génération de nombres véritablement aléatoires.

<b>StandardMinimal</b> : Le générateur StandardMinimal montre seulement 1 p-valeur inférieure à 0,01 lors du test d'ordre. Cela suggère qu'il peut produire des séquences de nombres aléatoires relativement bien réparties, similaires au Mersenne-Twister.

<b>VonNeumann</b> : Le générateur VonNeumann présente un nombre élevé de 83 p-valeurs inférieures à 0,01 lors du test d'ordre. Cela indique qu'il peut produire des séquences de nombres présentant des structures ou des biais significatifs, les rendant moins souhaitables pour des applications nécessitant une génération de nombres aléatoires de haute qualité.

Nous avons testé le générateur RANDU sur 100 graines différentes et que vous obtenez des résultats relativement bons lors du test d'ordre, cela pourrait être dû à la chance ou à des particularités des graines spécifiques que nous avons utilisées. RANDU peut, dans certains cas, générer des séquences qui semblent aléatoires ou qui passent certains tests statistiques, mais il reste un générateur de nombres pseudo-aléatoires de mauvaise qualité sur le long terme.
```{r}

#Calcul de la p_value moyenne pour chacun des générateurs
avg_pvalue_RANDU <- mean(order_RANDU)
avg_pvalue_SM <- mean(order_SM)
avg_pvalue_VonNeumann <- mean(order_VonNeumann)
avg_pvalue_MersenneTwister <- mean(order_MersenneTwister)
```
Aussi, nous avons calculé la p_value moyenne pour chaque séquence générée :

* RANDU : 0.48
* StandardMinimal : 0.49
* Von Neumann : 0.008
* Mersenne-Twister : 0.52

Mersenne-Twister reste le meilleur générateur en terme de qualité des nombres générés, tandis que Von Neumann est celui qui présente les plus mauvaises performances.
Le générateur RANDU n'est pas réputé pour présenter de bons résultats lors du test d'ordre, mais plutôt pour échouer à ce test.


# Application aux files d'attente

### Question 6
```{r}
FileMM1 <- function(lambda, mu, D){
  
  # On génère la premiere valeur d'arrivée qui suit une loi exponentielle de parametre lambda
  arrivee1 <- rexp(1,lambda)
  # fin represente la valeur maximale d'arrivée d'un client
  fin <- arrivee1 + D
  
  #Vecteur contenant les temps d'arrivé des clients
  arrivees <- c()
  arrivees <- c(arrivees,arrivee1)
  
  it <- 2
  # tant que l'heure d'arrivée du dernier client est inférieur à fin on rajoute une valeur d'heure d'arrivée qui correspond à l'heure d'arrivée du client précédent + une valeur générée par la loi exponentionnel
  while(arrivees[length(arrivees)] < fin )
  {
    arrivees <- c(arrivees, arrivees[it-1] + rexp(1,lambda))
    it <- it + 1
  }
  
  arrivees <- arrivees[-length(arrivees)] 
  
  #de la meme maniere, on génère l'heure de départ du premier client
  depart1 <- arrivee1 + rexp(1,mu)
  departs <- c()
  departs<- c(departs, depart1)
  
  for(i in 2:length(arrivees)) {
    # Deux cas possibles : le client arrive lorsqu'il n'y a personne, dans ce cas son heure de départ vaut arrivée + le temps de traitement par le magasin
    # le client arrive et il y a la queue : son heure de départ vaut l'heure de départ du client juste devant lui dans la queue + le temps de traitement de sa demande par le magasin
    departs <- c(departs , max(arrivees[i],departs[i-1]) + rexp(1,mu))
    
    # Si le service ferme, on garde les gens prisonniers
    if(departs[i] > arrivee1 + D){
      departs <- departs[-length(departs)]
      break
    }
    
  }
 
  ma_liste <- list(a = arrivees, d = departs)
  
  return (ma_liste)

}
```

### Question 7
```{r}
evolution_nb_clients <- function(arrivees , departs){

  #on créer deux data frame qui contiennent les heures d'arrivées et de départs de clients ainsi qu'un tag valant -1 si l'horaire correspond à une heure de départ et 1 si elle correspond à une heure d'arrivée
  a_df <- data.frame(Temps = arrivees, Tag = rep(1,length(arrivees)))
  d_df <- data.frame(Temps = departs, Tag = rep(-1,length(departs)))
  
  # On concatene ces deux data frame
  timeline <- rbind(a_df, d_df)
  
  # On trie le data frame dans l'ordre croissant et on fait une somme cumulée des tags. Cela représente le nombre de clients dans la file à chaque arrivée de client.
  timeline <- timeline[order(timeline$Temps), ]
  timeline$nb_clients <- cumsum(timeline$Tag)
  
  return (timeline)
}
```

```{r}

ma_liste1 <- FileMM1(10,20,12)
df1 <- evolution_nb_clients(ma_liste1$a, ma_liste1$d)

ma_liste2 <- FileMM1(14,20,12)
df2 <- evolution_nb_clients(ma_liste2$a, ma_liste2$d)


ma_liste3 <- FileMM1(20,20,12)
df3 <- evolution_nb_clients(ma_liste3$a, ma_liste3$d)


ma_liste4 <- FileMM1(30,20,12)
df4 <- evolution_nb_clients(ma_liste4$a, ma_liste4$d)


plot(df1$Temps, df1$nb_clients, type ='p' , col = "black" , xlab = "time" , ylab = "nb_clients" , main = "Evolution du nombre de clients en attente 10 arrivées/heure")
plot(df2$Temps, df2$nb_clients, type ='p' , col = "black" , xlab = "time" , ylab = "nb_clients" , main = "Evolution du nombre de clients en attente 14 arrivées/heure")
plot(df3$Temps, df3$nb_clients, type ='p' , col = "black" , xlab = "time" , ylab = "nb_clients" , main = "Evolution du nombre de clients en attente 20 arrivées/heure")
plot(df4$Temps, df4$nb_clients, type ='p' , col = "black" , xlab = "time" , ylab = "nb_clients" , main = "Evolution du nombre de clients en attente 30 arrivées/heure")


```
#### Commentaires :
On remarque que le nombre de clients en simultané reste acceptable dans les 2 premiers cas. Dans les cas où lambda et mu valent respectivement 20, 20 et 30,20 on remarque que le nombre de personne dans le magasin en simultané est croissant. La file d'attente deviens quasiment interminable.

### Question 8 : Calcul du nombre de client moyen

Le calcul du nombre de clients moyen en attente se fait en prenant la moyenne pondérée par la durée d'attente. L'implémentation par dataframe permet d'utiliser la fonction weighted.mean.


```{r}
mean1 <- weighted.mean(df1$nb_clients, w = c(0,diff(df1$Temps)))
mean2 <- weighted.mean(df2$nb_clients, w = c(0,diff(df2$Temps)))
mean3 <- weighted.mean(df3$nb_clients, w = c(0,diff(df3$Temps)))
mean4 <- weighted.mean(df4$nb_clients, w = c(0,diff(df4$Temps)))
```

```{r}
temps_presence <- function(arrivee, depart) {
  delta <- c()
  for(i in seq_along(depart)) {
    delta <- c(delta, depart[i]-arrivee[i])
  }
  
  return(mean(delta))

}
```

```{r}
Ew1 <- temps_presence(ma_liste1$a, ma_liste1$d)
Ew2 <- temps_presence(ma_liste2$a, ma_liste2$d)
Ew3 <- temps_presence(ma_liste3$a, ma_liste3$d)
Ew4 <- temps_presence(ma_liste4$a, ma_liste4$d)
```
#### Commentaire :
On s'appercoit que le nombre de clients moyen en simultané est très élevé dans le cas 2 et 3. Les clients attendent plusieurs minutes en moyenne pour être pris en charge. 
Problème car on ne retrouve pas la loi de Little?

